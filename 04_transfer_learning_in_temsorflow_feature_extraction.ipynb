{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTE49LYA0zLDFdbDhrkcvK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/debanandasen/Tensorflow/blob/main/04_transfer_learning_in_temsorflow_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning with Tensorflow Part 1: Feature Extraction\n",
        "\n",
        "There are two main benefits to using transfer learning:\n",
        "\n",
        "1) Can leverage an existing neural network architecture proven to work on\n",
        "   problems similar to our own.\n",
        "   \n",
        "2) Can leverage a working neural network architecture which has already learned\n",
        "   patterns on similar data to our own. This often results in achieving great results with less custom data."
      ],
      "metadata": {
        "id": "G19e8MCSakd6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9ucD-6g9rMo"
      },
      "outputs": [],
      "source": [
        "# Add timestamp\n",
        "import datetime\n",
        "print(f\"Notebook last run (end-to-end): {datetime.datetime.now()}\")\n",
        "\n",
        "\n",
        "# Are we running a GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Transfer Learning with Tensorflow HUb: with 10% of the data"
      ],
      "metadata": {
        "id": "1R7KKI6m-3B_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and becoming one with Data\n",
        "import zipfile\n",
        "# Downlaod Data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# unzip the downloaded file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "z0QTK4wDdBT5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# How many images in each folder ?\n",
        "\n",
        "import os\n",
        "\n",
        "# Walk through 10 percent data dictionary and list number of files\n",
        "for dirpath,dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} impages in '{dirpath}'.\")\n"
      ],
      "metadata": {
        "id": "5yVmcsTPdRCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create data loaders (Preparing the data)"
      ],
      "metadata": {
        "id": "ZC50M4z-shhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data inputs\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224,224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training Images:\")\n",
        "\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size=IMAGE_SHAPE,\n",
        "                                                          batch_size=BATCH_SIZE,\n",
        "                                                          class_mode=\"categorical\")\n",
        "\n",
        "print(\"Testing Images\")\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                             target_size=IMAGE_SHAPE,\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CgQs5D_kfGY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks( things to run whilst our model trains)"
      ],
      "metadata": {
        "id": "mIzreq1Nw6IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gen_linalg_ops import log_matrix_determinant_eager_fallback\n",
        "# Create TensorBoard callback\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name,experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir =log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "UI1j24NstrPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating model using tensorflow Hub\n",
        "Feature vector model link\n",
        "https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\n"
      ],
      "metadata": {
        "id": "yhf-LnLn0uEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare the following tow model\n",
        "resnet_url =\"https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/5\"\n",
        "\n",
        "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\""
      ],
      "metadata": {
        "id": "Og-azX0t0pQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "0cfTDIXM-eyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let's make a create_model() function to create a model frol url\n",
        "def create_model(model_url, num_classes=10):\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                           trainable=False,\n",
        "                                           name=\"feature_extraction_layer\",\n",
        "                                           input_shape=IMAGE_SHAPE+(3,))\n",
        "\n",
        "  # Create our own model\n",
        "  model = tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      layers.Dense(num_classes, activation=\"softmax\", name = \"output_layer\")\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "5AlbX_y2-1Wn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating and testing ResNet Tensorflow  Hub Feature Extraction model"
      ],
      "metadata": {
        "id": "osGAprWcDz8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Resnet Model\n",
        "resnet_model = create_model(resnet_url,\n",
        "                            num_classes=train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "id": "3SjvtZusB0K6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes=train_data_10_percent.num_classes"
      ],
      "metadata": {
        "id": "DfA9JWCwEbRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile our resnet model\n",
        "\n",
        "resnet_model.compile(loss=\"categorical_crossentropy\",\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "yKWAdK-q15LO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "2JzIMlsiE_W_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's fit our ResNet model to the data\n",
        "\n",
        "resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "                                  epochs=5,\n",
        "                                  steps_per_epoch=len(train_data_10_percent),\n",
        "                                  validation_data=test_data,\n",
        "                                  validation_steps=len(test_data),\n",
        "                                  callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                                         experiment_name=\"resnet50v2\")])\n",
        "\n"
      ],
      "metadata": {
        "id": "ZupIyFZ-FFbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss Curves"
      ],
      "metadata": {
        "id": "ZRPeeyF5AOOZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the validation and training curves\n",
        "def plot_loss_curves(history):\n",
        " loss = history.history[\"loss\"]\n",
        " val_loss = history.history[\"val_loss\"]\n",
        "\n",
        " accuracy = history.history[\"accuracy\"]\n",
        " val_accuracy = history.history[\"val_accuracy\"]\n",
        "\n",
        " epochs = range(len(history.history[\"loss\"]))\n",
        "\n",
        " # Plot loss\n",
        " plt.figure()\n",
        " plt.plot(epochs, loss, label=\"training_loss\")\n",
        " plt.plot(epochs, val_loss, label=\"val_loss\")\n",
        " plt.title(\"Loss\")\n",
        " plt.xlabel(\"Epochs\")\n",
        " plt.legend()\n",
        "\n",
        " # Plot accuracy\n",
        " plt.figure()\n",
        " plt.plot(epochs, accuracy, label=\"training_accuracy\")\n",
        " plt.plot(epochs, val_accuracy, label=\"val_accuracy\")\n",
        " plt.title(\"Accuracy\")\n",
        " plt.xlabel(\"Epochs\")\n",
        " plt.legend();"
      ],
      "metadata": {
        "id": "MqOYOXZG5DAJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(resnet_history)"
      ],
      "metadata": {
        "id": "faLqWmhDE5sH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating and testing EfficentNetB0 Tensorflow Hub Feature Extraction Model"
      ],
      "metadata": {
        "id": "upb97UI1OgRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating EfficentNet Feature Extractor Model\n",
        "efficientnet_model = create_model(model_url=efficientnet_url,\n",
        "                                  num_classes=train_data_10_percent.num_classes)\n",
        "\n",
        "# Compile The EfficientNet Model\n",
        "efficientnet_model.compile(loss=\"categorical_crossentropy\",\n",
        "                        optimizer=tf.keras.optimizers.Adam(),\n",
        "                         metrics=[\"accuracy\"])\n",
        "\n",
        "# Train Model with 10% of Training Data\n",
        "\n",
        "efficientnet_history = efficientnet_model.fit(train_data_10_percent,\n",
        "                                              epochs=5,\n",
        "                                              steps_per_epoch=len(train_data_10_percent),\n",
        "                                              validation_data=test_data,\n",
        "                                              validation_steps=len(test_data),\n",
        "                                              callbacks=[create_tensorboard_callback(dir_name=\"tensorflow_hub\",\n",
        "                                                                         experiment_name=\"efficientnetb0\")])"
      ],
      "metadata": {
        "id": "PF51gBfxGTzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(efficientnet_history)"
      ],
      "metadata": {
        "id": "Qz5CUBH-O_OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_model.summary()"
      ],
      "metadata": {
        "id": "JWISWmIYTfpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "f7NFshO4VrUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing our model results using TensorBoard\n",
        "  🔑 Note: When you upload things to tensorBoad.dev , your experiments are public.\n"
      ],
      "metadata": {
        "id": "PvjlzAgSYgxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#View your TensorBoard at https://tensorboard.dev/experiment/RKFX2V4BTV6RUYk9CEIORQ/\n",
        "!tensorboard dev list"
      ],
      "metadata": {
        "id": "G1BEB3bFbDjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQVI6-UcdBx2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}